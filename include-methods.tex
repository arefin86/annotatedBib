
\clearpage
\section{Research Methods}
% This section lists references related to \emph{research methods}, including but not limited to
% \emph{quantitative methods},
% \emph{qualitative methods},
% \emph{mixed methods} and
% \emph{academic writing}. 

%\citeSK{lakatos1980methodology} 
\citeSK{bensabat1987case}
		\begin{quote}
		\small
		In this highly-cited paper the authors discuss {\em case study research},
		a qualitative technique particularly effective for 
		``sticky, practice-based problems where the experience of the actors are
		important and the context of action is critical'', which fits the description
		of design problems.
		\end{quote}

%\citeSK{feyerabend1993against} 
\citeSK{cross1993science}
		\begin{quote}
		\small
		This paper discusses the field of 
		``design methodology'', a rather recent field of inquiry, and gives 
		an overview of recent advances:
		1) the development of design methods: systematic methods,
		2) the management of design process: models and strategies for executing design projects,
		3) the structure of design problems: theoretical analysis of the nature of design problems,
		4) the nature of design activity: empirical observations of design practice,
		5) the philosophy of design method: philosophical analysis and reflection on design activity.
		\end{quote}


\citeSK{guba1994competing}
		\begin{quote}
		\small
		Chapter 4 of the handbook explores in depth the following four paradigms in inquiry:
		1) positivism,
		2) postpositivism (which includes one important component: 
		determination, or cause and effect thinking),
		3) critical theory, and
		4) constructivism. The authors go on to discuss the distinction between qualitative
		and quantitative methods, critiques (of respective views), the nature of paradigms as
		basic belief systems, inter-paradigm and cross-paradigm analyses, and practical issues.
		\end{quote}

\citeSK{dorst1995comparing}
		\begin{quote}
		\small
		The authors examine two main and fundamentally different paradigms 
		(Simon's {\em rational problem solving process} and 
		Sch{\"o}n's {\em process of reflection-in-action}) 
		for looking at design activities. The conclusion is that Simon's model
		is appropriate for clear-cut design problems, and if the designer already has pre-defined
		problem-solving strategies.
		Sch{\"o}n's model is adequate for seeing design as a process where it's difficult
		to remove links between 1) the content of the design, and 2) design decisions.
		\end{quote}

\citeSK{march1995design}
		\begin{quote}
		\small
		There are two types of research related to IT, {\em descriptive research} (aspires
		to contribute to our understanding of IT, and is the equivalent of natural sciences in IT),
		and {\em prescriptive research} (whose goal is to better the performance of IT, and
		is the equivalent of design science).
		The paper proposes a framework for research in IT which reconciles these two streams of
		research, with the following two dimensions (Fig. \ref{fig:march1995design}):\\
		1) types of design science and natural science research activities:
		{\em build}, {\em evaluate}, {\em theorize}, and {\em justify}.\\
		2) types of outputs produced by design research: 
		{\em representational constructs}, {\em models}, {\em methods}, and {\em instantiations}. 
		\begin{figure}[htb]
		\begin{center}
		\includegraphics[width=3in]{figures/march1995design.jpg}
		\caption{Research framework in IT by March and Smith \cite{march1995design}.}
		\label{fig:march1995design}
		\end{center}
		\end{figure}		
		\end{quote}

\citeSK{lloydbryan1995can}
		\begin{quote}
		\small
		The authors claim that concurrent verbal reports (and the associated protocol analysis) 
		obtained by asking a designer to design and ``think aloud'' 
		are the best way to explore some aspect of design thinking, especially the interaction 
		between design problem and design solution. On the other hand, protocol analysis 
		impairs the very activity of designing.
		\end{quote}

%\citeSK{kuhn1996structure} 
%\citeSK{popper2002logic} 

\citeSKextended{jacko2003hci}{Chapter 50: Blomberg, Burrell, Guest: {\em An Ethnographic Approach to Design}}
		\begin{quote}
		\small
		Chapter 50 of the book describes ethnography within its historical and contemporary contexts,
		delineates its guiding principles, describes methods and techniques, and
		gives several case studies illustrating the application of ethnographic methods
		in the field of HCI.
		\end{quote}

\citeSK{booth2003craft}
		\begin{quote}
		\small
		This book focuses on core properties of research, without delving into any particular methodology.
		It explains how to establish a good connection between researchers (i.e. report writers) and readers,
		how to go about finding interesting topics and research questions with high significance and relevance,
		the difference between practical and research problems (and how to find good/relevant latter ones),
		finding sources (with separate section on the ethics of using people as sources),
		making research claims and how to support them (reasons, evidence, acknowledgments, responses, warrants),
		and how to perform planning, drafting and revising of written materials.
		\end{quote}

%\citeSK{lehman2005jmp}

% \citeSK{hewett2005creativity}
% 		\begin{quote}
% 		\small
% 		This paper
% 		\end{quote}

% \citeSK{wolf2006dispelling}
% 		\begin{quote}
% 		\small
% 		This paper argues that the scientific method isn't the best method to evaluate
% 		usability of computational tools.
% 		\end{quote}
		
\citeSK{north2006toward}
		\begin{quote}
		\small
		This article examines what it means to evaluate a visualization, and claims
		that the purpose of (or one of many purposes of) visualization is {\em insight}.
		Some important characteristics of insight are:
		complex, deep, qualitative, unexpected, and relevant.
		Existing evaluation methods:
		controlled experiments (the focus of this article),
		usability testing,
		longitudinal studies,
		and analytical methods (for example, heuristic evaluation, cognitive walkthroughs, etc.)
		The author claims that new evaluation methods, which attempt to measure directly,
		are needed.
		\end{quote}

\citeSK{shneiderman2006strategies}
		\begin{quote}
		\small
		The authors present MILC, a research method especially suited for 
		ethnography-oriented and longitudinal participant observation (as distinguished
		from conventional, tightly-controlled laboratory experiments):\\
		- M stands for {\em multi-dimensional}, implying the use of observations, interviews, surveys
		and logging to assess user performance and the effectiveness of the interface.\\
		- I stands for {\em in-depth}, implying that researches engage with expert users
		up to the point of becoming personal assistants.\\
		- L stands for {\em long-term}, implying that the study lasts from novice stage all the
		way to the expert stage.\\
		- C stands for {\em case studies}, implying that users work on concrete, well-delineated 
		problems.
		\end{quote}

\citeSK{creswell2007designing}
		\begin{quote}
		\small
		This book describes how to combine both qualitative and quantitative methods 
		(and data) in a study,
		thus allowing for a better understanding of the studied phenomenon, compared to using
		either one of the method only by itself.
		It also discusses the types of problems suitable for mixed-method aproach, and 
		describes four main mixed-method study designs:
		1) {\em embedded} (qualitative data used in an experiment),
		2) {\em exploratory} (explaining quantitative with qualitative data),
		3) {\em triangulated} (qualitative and quantitative data collected simultaneously), and
		4) {\em explanatory} (using qualitative data to devise a quantitative method). 
		\end{quote}

\citeSK{pedgley2007capturing}
		\begin{quote}
		\small
		How to create a convincing research evidence using researcher's own
		design activity ({\em practice-led research}). The author comes up with
		three main methodologies:
		1) {\em participant observation} (i.e. taking notes on designer's externally perceptible activities),
		2) {\em action research} (extension of participant observation: designer initiates and evaluates
		effects of planned intervention on social situation), and
		3) {\em diaries}.
		\end{quote}

\citeSK{zimmerman2007research}
		\begin{quote}
		\small
		Two contributions of the paper:
		1) a model of interaction design research (Fig. \ref{fig:zimmerman2007research}), and
		2) a set of criteria for evaluating the quality of an interaction design research contribution.
		\begin{figure}[htb]
		\begin{center}
		\includegraphics[width=4in]{figures/zimmerman2007research.jpg}
		\caption{Model of interaction design research, Zimmerman et al \cite{zimmerman2007research}.}
		\label{fig:zimmerman2007research}
		\end{center}
		\end{figure}		
		\end{quote}

\citeSK{vaishnavi2007design}
		\begin{quote}
		\small
		This resource gives an extensive overview of design science research in the field
		of Information Systems (IS), along
		with its epistemological, ontological and philosophical foundations.
% 		Elaborates on all phases of design science research method: artifact design,
% 		construction, analysis, and evaluation.
		\end{quote}

%\citeSK{greene2008mixed}

% \citeSK{creswell2008research}
% 		\begin{quote}
% 		\small
% 		TBD
% 		\end{quote}

\citeSK{kees2008design}
		\begin{quote}
		\small
		The paper defends a bold claim that we are at the cusp of a Kuhnian revolution in design research.
		Anomalies are accumulating, and they can't be resolved using conventional tools and
		methodologies.
		The author suggests two ways to move forward:
		1) creating a framework to describe 'the designer', including his/her development of expertise, and
		2) creating a framework to describe design practice.
		\end{quote}

\citeSK{greenberg2008usability}
		\begin{quote}
		\small
		The paper argues that conventional usability evaluation methods (based in large
		part in quantitative empirical methods) aren't always the best way to evaluate human-computer interfaces.
		When not done right, such methods can effectively prune and eliminate creative ideas
		that fall outside of the norm. Moreover, in a great part of HCI work,
		researchers usually develop a prototype, and then try to find at least one
		case where the prototype performs better than some older tool---this is, at 
		best, {\em weak science} because it does not try to refute a hypothesis which
		then shows resilience in spite of (ideally, numerous) refutal attempts. 
		The authors thus claim that the methodology chosen to 
		evaluate human-computer interfaces must be adapted for the HCI design 
		problem at hand, and that premature evaluation can do more harm than it's worth.	
		
		Finally, the authors give an useful list of guidelines of how to proceed and
		remedy the problem of prematurely evaluating human-computer interfaces:\\
		- usability evaluation is just one tool in our toolkit of validating the interface,\\
		- at all times in research, we have to decide whether usability evaluation would be
		  meaningful or not, and if not, we have to find other ways to validate the interface.\\
		- HCI community has to stop insisting on formal evaluation, and accept other
		  ways to validate an interface: design rationale, vision, expected scenarios of use,
		  reflections, case studies, critiques, and so on; at a minimum, why the interface
		  was built like that, lessons learned, expected problems, how it fits into
		  current state of knowledge, etc.\\
		- favour rigorous science, instead of weak science. For novel systems,
		  existence proofs are acceptable.  For modest variations of established 
		  ideas, risky hypothesis testing is favoured. Also, replication of results should be encouraged.\\
		- looking to other disciplines to consider how they judge design worthiness.  
		\begin{figure}[htb]
		\begin{center}
		\includegraphics[width=0.99\textwidth]{figures/greenberg2008usability.jpg}
		\caption{
		Continuum: sketches-to-prototypes of human-computer interfaces (left),
		and the dillemma (right): getting the design right?, or: getting the right design?
		\citeauthor{greenberg2008usability}: 
		\citetitle{greenberg2008usability} 
		\cite{greenberg2008usability}.}
		\label{fig:greenberg2008usability}
		\end{center}
		\end{figure}
		
		\end{quote}

			
\citeSK{carroll2009creativity}
		\begin{quote}
		\small
		Presents Creativity Support Index (CSI), meant to measure objectively the level of 
		creativity support a system is offering. CSI consists of six factors:
		exploration,
		expressiveness,
		enjoyment,
		immersion,
		collaboration, and
		results worth effort.
		\end{quote}


\newpage
%\nocite{*}

\newpage
\printbibliography %[title={References Sorted by First Author}]

% \newpage
% \printbibliography[type=book,title={List of Books}]
% 
% \newpage
% \printbibliography[type=article,title={List of Articles}]

%\nocite{*}
%\bibliographystyle{plain-annote} 
%\bibliographystyle{apsr-annote}
%\bibliographystyle{apsr2001-annote}
%\bibliography{ann-bib}

\end{document}